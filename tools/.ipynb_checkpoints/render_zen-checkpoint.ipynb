{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "from multiprocessing import Process\n",
    "import time\n",
    "from timeit import default_timer as timer\n",
    "import multiprocessing as mp\n",
    "\n",
    "# output_folder = \"output_plane\"\n",
    "# job_filename = \"job_plane.txt\"\n",
    "# progress_filename = \"progress_plane.txt\"\n",
    "# folder_id = \"02691156\" # plane\n",
    "\n",
    "output_folder = \"output_car\"\n",
    "progress_filename = \"progress_car.txt\"\n",
    "job_filename = \"job_car.txt\"\n",
    "folder_id = \"02958343\"\n",
    "\n",
    "# output_folder = \"output_chair\"\n",
    "# progress_filename = \"progress_chair.txt\"\n",
    "# job_filename = \"job_chair.txt\"\n",
    "# folder_id = \"03001627\" # chair\n",
    "\n",
    "\n",
    "# shapnet_path = \"/NAS/data/shapenet/ShapeNetCore.v2\"\n",
    "# render_path = \"/NAS/home/6dof/models/research/keypointnet/tools/\"\n",
    "\n",
    "shapnet_path = \"/home/paperspace/zen/6dof/6dof_data/ShapeNetCore.v1\"\n",
    "render_path = \"/home/paperspace/zen/6dof/models/research/keypointnet/tools/\"\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "f = open( render_path + job_filename,\"r\") \n",
    "f_save = open( render_path + progress_filename,\"r+\") \n",
    "ids = []\n",
    "done_ids = []\n",
    "for s in f:\n",
    "    ids.append(s.split(\",\")[1])\n",
    "ids = ids[1:]\n",
    "for s in f_save:\n",
    "    done_ids.append(s.strip())\n",
    "f_save.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = os.listdir(shapnet_path)\n",
    "all_ids = []\n",
    "for i in dirs:\n",
    "    file_path = os.path.join(shapnet_path,i)\n",
    "    if os.path.isdir(file_path):\n",
    "        all_ids += os.listdir(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/home/paperspace/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:46: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished: a2b758aa5d51642bd32761b337f8b72a\n",
      "finished: 2cf6583a74dc4d1e373ed874fe97420b\n",
      "finished: 14282db0ca4238429a6e43b878d5b335\n",
      "finished: 24fbe7a49fd786c5fb5c1b0f759e2bc1\n",
      "finished: b5b6f5ed2031f34cec7a415ac918303f\n",
      "finished: a14b262838529c2c81e1d9f6b27f1a92\n",
      "finished: 76f142e62adc0f2ae768735f27170bc4\n",
      "finished: b64f57298cf3e4328b96ae1a0a8b84ec\n",
      "finished: 12c66a0490b223be595dc3191c718398\n",
      "finished: fd41d04f1aabbaea3fddedb0bf24c68a\n",
      "finished: 4658a2fb7353f839643ae903098a314\n",
      "finished: 93ba822e84586999e3375a6b96a1d765\n",
      "finished: d171967c6353177bb87697d3904b168b\n",
      "finished: e8d5a3e98c222583d972c9dd75ed77d4\n",
      "finished: b6d61068ef2bf2d46059aeb39e538eb2\n",
      "finished: b34526d94a00ab55f5a25dd70eb863e0\n",
      "finished: 7934ca36e240e91d5e9e2656aff7dd5b\n",
      "finished: 2628b6cfcf1a53465569af4484881d20\n",
      "finished: af71e72822241808a8ab13c300600dba\n",
      "finished: 9c9d6469ecdfc54fc2a9d7232db0ed61\n",
      "finished: 444d67950ff9a4cc1139bebb00fe5be8\n",
      "finished: 3a6d6534045b1895e8ed194c80e0b1ef\n",
      "finished: 22e4e0210f80fae813940713146922c1\n",
      "finished: 795e0051d9ce7dfe384d4ad42dbd0045\n",
      "finished: af73d05ac86369bf4ce863ea27e2b897\n",
      "finished: bfcc89117315f3da90b1d6deb98feec6\n",
      "finished: e3473fc8fffca7d4d972c9dd75ed77d4\n",
      "finished: d8e8540acddacf98c1006ed55bc1a3fc\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import misc\n",
    "import tensorflow as tf\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "# output_dir = \"/home/paperspace/zen/6dof/6dof_data/zen_plane/\"\n",
    "# input_dir = \"/home/paperspace/zen/6dof/models/research/keypointnet/tools/output_plane/02691156/\"\n",
    "\n",
    "def get_matrix(lines):\n",
    "    return np.array([[float(y) for y in x.strip().split(\" \")] for x in lines])\n",
    "\n",
    "\n",
    "def read_model_view_matrices(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    return get_matrix(lines[:4]), get_matrix(lines[4:])\n",
    "\n",
    "\n",
    "def bytes_feature(values):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[values]))\n",
    "\n",
    "\n",
    "def generate(files, output_dir, input_dir, chunk_size = 40):\n",
    "    file_chunks = [files[i:i + chunk_size] for i in range(0, len(files), chunk_size)]\n",
    "    for i in range(len(file_chunks)):\n",
    "        files = file_chunks[i]\n",
    "        record_name = output_dir + '{0:04}'.format(i) + \".tfrecord\"\n",
    "        with tf.python_io.TFRecordWriter(record_name) as tfrecord_writer:\n",
    "            with tf.Graph().as_default():\n",
    "                im0 = tf.placeholder(dtype=tf.uint8)\n",
    "                im1 = tf.placeholder(dtype=tf.uint8)\n",
    "                encoded0 = tf.image.encode_png(im0)\n",
    "                encoded1 = tf.image.encode_png(im1)\n",
    "                with tf.Session() as sess:\n",
    "                    for file_name in files:\n",
    "                        count = 0\n",
    "                        indir = input_dir + file_name  + \"/\"\n",
    "                        while tf.gfile.Exists(indir + \"%06d.txt\" % count):\n",
    "                            image0 = misc.imread(indir + \"%06d.png\" % (count * 2))\n",
    "                            image1 = misc.imread(indir + \"%06d.png\" % (count * 2 + 1))\n",
    "\n",
    "                            mat0, mat1 = read_model_view_matrices(\n",
    "                                indir + \"%06d.txt\" % count)\n",
    "\n",
    "                            mati0 = np.linalg.inv(mat0).flatten()\n",
    "                            mati1 = np.linalg.inv(mat1).flatten()\n",
    "                            mat0 = mat0.flatten()\n",
    "                            mat1 = mat1.flatten()\n",
    "\n",
    "                            st0, st1 = sess.run([encoded0, encoded1],\n",
    "                                                feed_dict={im0: image0, im1: image1})\n",
    "\n",
    "                            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                                'img0': bytes_feature(st0),\n",
    "                                'img1': bytes_feature(st1),\n",
    "                                'mv0': tf.train.Feature(\n",
    "                                    float_list=tf.train.FloatList(value=mat0)),\n",
    "                                'mvi0': tf.train.Feature(\n",
    "                                    float_list=tf.train.FloatList(value=mati0)),\n",
    "                                'mv1': tf.train.Feature(\n",
    "                                    float_list=tf.train.FloatList(value=mat1)),\n",
    "                                'mvi1': tf.train.Feature(\n",
    "                                    float_list=tf.train.FloatList(value=mati1)),\n",
    "                            }))\n",
    "\n",
    "                            tfrecord_writer.write(example.SerializeToString())\n",
    "                            count += 1\n",
    "                        print(\"finished: \" + file_name)\n",
    "    \n",
    "# if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('-t', '--target', dest='target',\n",
    "#                         required=True,\n",
    "#                         help='target set: car, plane, chair')\n",
    "\n",
    "\n",
    "#     if '--' not in sys.argv:\n",
    "#         parser.print_help()\n",
    "#         exit(1)\n",
    "\n",
    "#     argv = sys.argv[sys.argv.index('--') + 1:]\n",
    "#     args, _ = parser.parse_known_args(argv)\n",
    "#     if args.target == 'car':\n",
    "#         output_dir = \"/NAS/home/shapenet_rendering/shapenet_car/cars_with_keypoints/\"\n",
    "#         input_dir = \"/NAS/home/shapenet_rendering/shapenet_car/02958343/\"\n",
    "#     elif args.target == \"plane\":\n",
    "#         output_dir = \"/NAS/home/shapenet_rendering/shapenet_plane/planes_with_keypoints/\"\n",
    "#         input_dir = \"/NAS/home/shapenet_rendering/shapenet_plane/02691156/\"\n",
    "#     elif args.target == \"chair\":\n",
    "#         output_dir = \"/NAS/home/shapenet_rendering/shapenet_chair/chairs_with_keypoints/\"\n",
    "#         input_dir = \"/NAS/home/shapenet_rendering/shapenet_chair/03001627/\"\n",
    "#     else:\n",
    "#         parser.print_help()\n",
    "#         exit(1)\n",
    "output_dir = \"/home/paperspace/zen/6dof/6dof_data/zen_plane/\"\n",
    "input_dir = \"/home/paperspace/zen/6dof/models/research/keypointnet/tools/output_plane/02691156/\"\n",
    "files = os.listdir(input_dir)\n",
    "\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "generate(files, output_dir, input_dir, 40)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 40\n",
    "file_chunks = [files[i:i + chunk_size] for i in range(0, len(files), chunk_size)]\n",
    "for i in range(len(file_chunks)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "a2b758aa5d51642bd32761b337f8b72a; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-31113b22e005>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mrecord\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_record_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/lib/io/tf_record.py\u001b[0m in \u001b[0;36mtf_record_iterator\u001b[0;34m(path, options)\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     reader = pywrap_tensorflow.PyRecordReader_New(\n\u001b[0;32m---> 74\u001b[0;31m         compat.as_bytes(path), 0, compat.as_bytes(compression_type), status)\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreader\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    527\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: a2b758aa5d51642bd32761b337f8b72a; No such file or directory"
     ]
    }
   ],
   "source": [
    "files = [output_dir + i for i in os.listdir(output_dir)]\n",
    "for fn in files:\n",
    "    c = 0\n",
    "    for record in tf.python_io.tf_record_iterator(fn):\n",
    "        c += 1\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
